{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**웹캠**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from keras.models import load_model\n",
    "from keras.layers import DepthwiseConv2D\n",
    "import cv2  \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/youngjin/Desktop/cabdi2024/keras_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m      2\u001b[0m                    custom_objects\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDepthwiseConv2D\u001b[39m\u001b[38;5;124m'\u001b[39m: DepthwiseConv2D}, \n\u001b[0;32m      3\u001b[0m                    \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m class_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/youngjin/Desktop/cabdi2024/labels.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[0;32m      8\u001b[0m camera \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "model = load_model(\"C:/Users/youngjin/Desktop/cabdi2024/keras_model.h5\", \n",
    "                   custom_objects={'DepthwiseConv2D': DepthwiseConv2D}, \n",
    "                   compile=False)\n",
    "\n",
    "class_names = open(\"C:/Users/youngjin/Desktop/cabdi2024/labels.txt\", \"r\").readlines()\n",
    "\n",
    "\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, image = camera.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Failed to grab camera image\")\n",
    "        break\n",
    "\n",
    "\n",
    "    if image is None:\n",
    "        print(\"Empty image\")\n",
    "        continue\n",
    "\n",
    "    resized_image = cv2.resize(image, (224, 224))\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Webcam Image\", resized_image)\n",
    "\n",
    "\n",
    "    image = np.asarray(resized_image, dtype=np.float32)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "\n",
    "    image = image / 255.0\n",
    "\n",
    "\n",
    "    prediction = model.predict(image)\n",
    "    index = np.argmax(prediction)\n",
    "    class_name = class_names[index]\n",
    "    confidence_score = prediction[0][index]\n",
    "\n",
    "\n",
    "    print(\"Class:\", class_name[2:], end=\"\")\n",
    "    print(\"Confidence Score:\", str(np.round(confidence_score * 100))[:-2], \"%\")\n",
    "\n",
    "\n",
    "    keyboard_input = cv2.waitKey(1)\n",
    "\n",
    "\n",
    "    if keyboard_input == 27:\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\youngjin\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\youngjin\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\youngjin\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Class: nasi putih Confidence Score: 100 %\n",
      "인식된 음식: nasi putih. 맞습니까? (y/n)\n",
      "식재료에 맞는 레시피가 없습니다.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.layers import DepthwiseConv2D\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def food_info(name, ingredients):\n",
    "    url = f\"https://www.10000recipe.com/recipe/list.html?q={name}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "    else:\n",
    "        print(\"HTTP 응답 오류:\", response.status_code)\n",
    "        return\n",
    "\n",
    "    food_list = soup.find_all(attrs={'class': 'common_sp_link'})\n",
    "    if not food_list:\n",
    "        print(\"식재료에 맞는 레시피가 없습니다.\")\n",
    "        return\n",
    "\n",
    "    recipes = []\n",
    "\n",
    "    for food in food_list:\n",
    "        food_id = food['href'].split('/')[-1]\n",
    "        new_url = f'https://www.10000recipe.com/recipe/{food_id}'\n",
    "        new_response = requests.get(new_url)\n",
    "        if new_response.status_code == 200:\n",
    "            html = new_response.text\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "        else:\n",
    "            print(\"HTTP 응답 오류:\", new_response.status_code)\n",
    "            continue\n",
    "\n",
    "        food_info = soup.find(attrs={'type': 'application/ld+json'})\n",
    "        if food_info is not None:\n",
    "            result = json.loads(food_info.text)\n",
    "            recipe_ingredients = result.get('recipeIngredient', [])\n",
    "            recipe = [step['text'] for step in result.get('recipeInstructions', [])]\n",
    "            for i in range(len(recipe)):\n",
    "                recipe[i] = f'{i + 1}. ' + recipe[i]\n",
    "\n",
    "            view_count_element = soup.find(attrs={'class': 'view_count'})\n",
    "            view_count = int(view_count_element.text.replace(',', '')) if view_count_element else 0\n",
    "\n",
    "            print(f\"레시피: {soup.title.string}, 조회수: {view_count}\")\n",
    "\n",
    "            recipes.append({\n",
    "                'title': soup.title.string,\n",
    "                'ingredients': recipe_ingredients,\n",
    "                'recipe': recipe,\n",
    "                'view_count': view_count\n",
    "            })\n",
    "\n",
    "    if recipes:\n",
    "        best_recipe = max(recipes, key=lambda x: x['view_count'])\n",
    "\n",
    "        # 추가적인 식재료 확인\n",
    "        if ingredients:\n",
    "            print(f\"추가적인 식재료: {', '.join(ingredients)}\")\n",
    "            best_recipe['ingredients'].extend(ingredients)\n",
    "\n",
    "        res = {\n",
    "            'name': best_recipe['title'],\n",
    "            'ingredients': ', '.join(best_recipe['ingredients']),\n",
    "            'recipe': best_recipe['recipe']\n",
    "        }\n",
    "        return res\n",
    "    else:\n",
    "        print(\"적합한 레시피를 찾지 못했습니다.\")\n",
    "        return\n",
    "\n",
    "# 모델과 라벨 로드\n",
    "model = load_model(\"C:/Users/youngjin/Desktop/cabdi2024/keras_model.h5\", \n",
    "                   custom_objects={'DepthwiseConv2D': DepthwiseConv2D}, \n",
    "                   compile=False)\n",
    "\n",
    "class_names = open(\"C:/Users/youngjin/Desktop/cabdi2024/labels.txt\", \"r\").readlines()\n",
    "\n",
    "# 웹캠 초기화\n",
    "camera = cv2.VideoCapture(0)\n",
    "is_recognizing = True\n",
    "additional_ingredients = []\n",
    "\n",
    "while True:\n",
    "    ret, image = camera.read()\n",
    "    if not ret:\n",
    "        print(\"웹캠 이미지 캡처 실패\")\n",
    "        break\n",
    "\n",
    "    resized_image = cv2.resize(image, (224, 224))\n",
    "    cv2.imshow(\"Webcam Image\", resized_image)\n",
    "\n",
    "    if is_recognizing:\n",
    "        image = np.asarray(resized_image, dtype=np.float32)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = image / 255.0\n",
    "\n",
    "        prediction = model.predict(image)\n",
    "        index = np.argmax(prediction)\n",
    "        class_name = class_names[index].strip()\n",
    "        confidence_score = prediction[0][index]\n",
    "\n",
    "        print(\"Class:\", class_name[2:], \"Confidence Score:\", str(np.round(confidence_score * 100))[:-2], \"%\")\n",
    "\n",
    "        if confidence_score > 0.5:  # 낮은 신뢰도 예측을 피하기 위한 임계값 설정\n",
    "            print(f\"인식된 음식: {class_name[2:]}. 맞습니까? (y/n)\")\n",
    "            while True:\n",
    "                keyboard_input = cv2.waitKey(1)\n",
    "                if keyboard_input == ord('y'):\n",
    "                    food_info_result = food_info(class_name[2:], additional_ingredients)\n",
    "                    if food_info_result:\n",
    "                        print(\"Food Name:\", food_info_result[\"name\"])\n",
    "                        print(\"Ingredients:\", food_info_result[\"ingredients\"])\n",
    "                        print(\"Recipe:\")\n",
    "                        for step in food_info_result['recipe']:\n",
    "                            print(step)\n",
    "                    is_recognizing = False  # 인식을 중단하고 다음 단계로 넘어감\n",
    "                    additional_ingredients = []  # 추가적인 식재료 초기화\n",
    "                    break\n",
    "                elif keyboard_input == ord('n'):\n",
    "                    print(\"레시피를 추천합니다.\")\n",
    "                    break\n",
    "                elif keyboard_input == ord('a'):\n",
    "                    print(\"레시피에 추가할 식재료가 있습니까? (y/n)\")\n",
    "                    additional_input = cv2.waitKey(0)\n",
    "                    if additional_input == ord('y'):\n",
    "                        ingredient_input = input(\"추가할 식재료를 입력하세요: \")\n",
    "                        additional_ingredients.append(ingredient_input)\n",
    "                    elif additional_input == ord('n'):\n",
    "                        print(\"추가적인 식재료 입력을 종료합니다.\")\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"잘못된 입력입니다.\")\n",
    "                elif keyboard_input == 27:  # ESC 키를 누르면 종료\n",
    "                    is_recognizing = False\n",
    "                    break\n",
    "\n",
    "    if not is_recognizing:\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\youngjin\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\youngjin\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\youngjin\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "웹캠 이미지 캡처 실패\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.layers import DepthwiseConv2D\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def food_info(name):\n",
    "    url = f\"https://www.10000recipe.com/recipe/list.html?q={name}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "    else:\n",
    "        print(\"HTTP 응답 오류:\", response.status_code)\n",
    "        return\n",
    "\n",
    "    food_list = soup.find_all(attrs={'class': 'common_sp_link'})\n",
    "    if not food_list:\n",
    "        print(\"식재료에 맞는 레시피가 없습니다.\")\n",
    "        return\n",
    "\n",
    "    recipes = []\n",
    "\n",
    "    for food in food_list:\n",
    "        food_id = food['href'].split('/')[-1]\n",
    "        new_url = f'https://www.10000recipe.com/recipe/{food_id}'\n",
    "        new_response = requests.get(new_url)\n",
    "        if new_response.status_code == 200:\n",
    "            html = new_response.text\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "        else:\n",
    "            print(\"HTTP 응답 오류:\", new_response.status_code)\n",
    "            continue\n",
    "\n",
    "        food_info = soup.find(attrs={'type': 'application/ld+json'})\n",
    "        if food_info is not None:\n",
    "            result = json.loads(food_info.text)\n",
    "            ingredients = result.get('recipeIngredient', [])\n",
    "            recipe = [step['text'] for step in result.get('recipeInstructions', [])]\n",
    "            for i in range(len(recipe)):\n",
    "                recipe[i] = f'{i + 1}. ' + recipe[i]\n",
    "\n",
    "            view_count_element = soup.find(attrs={'class': 'view_count'})\n",
    "            view_count = int(view_count_element.text.replace(',', '')) if view_count_element else 0\n",
    "\n",
    "            print(f\"레시피: {soup.title.string}, 조회수: {view_count}\")\n",
    "\n",
    "            recipes.append({\n",
    "                'title': soup.title.string,\n",
    "                'ingredients': ingredients,\n",
    "                'recipe': recipe,\n",
    "                'view_count': view_count\n",
    "            })\n",
    "\n",
    "    if recipes:\n",
    "        best_recipe = max(recipes, key=lambda x: x['view_count'])\n",
    "\n",
    "        res = {\n",
    "            'name': best_recipe['title'],\n",
    "            'ingredients': ', '.join(best_recipe['ingredients']),\n",
    "            'recipe': best_recipe['recipe']\n",
    "        }\n",
    "        return res\n",
    "    else:\n",
    "        print(\"적합한 레시피를 찾지 못했습니다.\")\n",
    "        return\n",
    "\n",
    "# 모델과 라벨 로드\n",
    "model = load_model(\"C:/Users/youngjin/Desktop/cabdi2024/keras_model.h5\", \n",
    "                   custom_objects={'DepthwiseConv2D': DepthwiseConv2D}, \n",
    "                   compile=False)\n",
    "\n",
    "class_names = open(\"C:/Users/youngjin/Desktop/cabdi2024/labels.txt\", \"r\").readlines()\n",
    "\n",
    "# 웹캠 초기화\n",
    "camera = cv2.VideoCapture(0)\n",
    "is_recognizing = True\n",
    "\n",
    "while True:\n",
    "    ret, image = camera.read()\n",
    "    if not ret:\n",
    "        print(\"웹캠 이미지 캡처 실패\")\n",
    "        break\n",
    "\n",
    "    resized_image = cv2.resize(image, (224, 224))\n",
    "    cv2.imshow(\"Webcam Image\", resized_image)\n",
    "\n",
    "    if is_recognizing:\n",
    "        image = np.asarray(resized_image, dtype=np.float32)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = image / 255.0\n",
    "\n",
    "        prediction = model.predict(image)\n",
    "        index = np.argmax(prediction)\n",
    "        class_name = class_names[index].strip()\n",
    "        confidence_score = prediction[0][index]\n",
    "\n",
    "        print(\"Class:\", class_name[2:], \"Confidence Score:\", str(np.round(confidence_score * 100))[:-2], \"%\")\n",
    "\n",
    "        if confidence_score > 0.5:  # 낮은 신뢰도 예측을 피하기 위한 임계값 설정\n",
    "            print(f\"인식된 음식: {class_name[2:]}. 맞습니까? (y/n)\")\n",
    "            while True:\n",
    "                keyboard_input = cv2.waitKey(1)\n",
    "                if keyboard_input == ord('y'):\n",
    "                    food_info_result = food_info(class_name[2:])\n",
    "                    if food_info_result:\n",
    "                        print(\"Food Name:\", food_info_result[\"name\"])\n",
    "                        print(\"Ingredients:\", food_info_result[\"ingredients\"])\n",
    "                        print(\"Recipe:\")\n",
    "                        for step in food_info_result['recipe']:\n",
    "                            print(step)\n",
    "                    is_recognizing = False  # 인식을 중단하고 다음 단계로 넘어감\n",
    "                    break\n",
    "                elif keyboard_input == ord('n'):\n",
    "                    is_recognizing = True  # 인식을 계속 진행\n",
    "                    break\n",
    "                elif keyboard_input == 27:  # ESC 키를 누르면 종료\n",
    "                    is_recognizing = False\n",
    "                    break\n",
    "\n",
    "    if not is_recognizing:\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.layers import DepthwiseConv2D\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\youngjin\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\youngjin\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"C:/Users/youngjin/Desktop/cabdi2024/keras_model.h5\", \n",
    "                   custom_objects={'DepthwiseConv2D': DepthwiseConv2D}, \n",
    "                   compile=False)\n",
    "\n",
    "class_names = open(\"C:/Users/youngjin/Desktop/cabdi2024/labels.txt\", \"r\").readlines()\n",
    "class_names = [name.strip() for name in class_names]  # 줄바꿈 문자 제거\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: 'C:/Users/youngjin/Desktop/cabdi2024/test_images'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m         labels\u001b[38;5;241m.\u001b[39mappend(label)\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mvstack(images), labels\n\u001b[1;32m---> 21\u001b[0m test_images, test_labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_images_from_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m, in \u001b[0;36mload_images_from_folder\u001b[1;34m(folder)\u001b[0m\n\u001b[0;32m      6\u001b[0m images \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      9\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder, filename)\n\u001b[0;32m     10\u001b[0m     img \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mload_img(img_path, target_size\u001b[38;5;241m=\u001b[39mimage_size)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: 'C:/Users/youngjin/Desktop/cabdi2024/test_images'"
     ]
    }
   ],
   "source": [
    "test_dir = \"C:/Users/youngjin/Desktop/cabdi2024/test_images\"\n",
    "image_size = (224, 224)  # 이미지 크기를 모델에 맞게 설정합니다.\n",
    "\n",
    "# 이미지와 레이블을 로드합니다.\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = image.load_img(img_path, target_size=image_size)\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        images.append(img_array)\n",
    "        \n",
    "        # 파일명에서 라벨 추출 (예: \"cat.0.jpg\" -> \"cat\")\n",
    "        label = filename.split('.')[0]\n",
    "        labels.append(label)\n",
    "    return np.vstack(images), labels\n",
    "\n",
    "test_images, test_labels = load_images_from_folder(test_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측을 수행합니다.\n",
    "predictions = model.predict(test_images)\n",
    "\n",
    "# 예측된 클래스 인덱스를 얻습니다.\n",
    "predicted_labels = [class_names[np.argmax(pred)] for pred in predictions]\n",
    "\n",
    "# 정확도를 계산합니다.\n",
    "correct_predictions = np.sum(np.array(predicted_labels) == np.array(test_labels))\n",
    "accuracy = correct_predictions / len(test_labels)\n",
    "\n",
    "print(f\"테스트 정확도: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**아두이노**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "import shutil\n",
    "from keras.models import load_model\n",
    "from keras.layers import DepthwiseConv2D\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "import serial\n",
    "import time\n",
    "\n",
    "def unzip_files(zip_path, extract_path):\n",
    "    shutil.unpack_archive(zip_path, extract_path)\n",
    "\n",
    "zip_path1 = 'C:/Users/youngjin/Desktop/캡디2024/Cheese.v1i.createml.zip'\n",
    "zip_path2 = 'C:/Users/youngjin/Desktop/캡디2024/onion.v1i.createml.zip'\n",
    "extract_path = 'C:/Users/youngjin/Desktop/캡디2024'\n",
    "\n",
    "unzip_files(zip_path1, extract_path)\n",
    "unzip_files(zip_path2, extract_path)\n",
    "\n",
    "cheese = zip_path1\n",
    "bread = zip_path2\n",
    "\n",
    "\n",
    "# Load the model\n",
    "model = load_model(\"C:/Users/youngjin/Desktop/캡디2024/keras_model.h5\", \n",
    "                   custom_objects={'DepthwiseConv2D': DepthwiseConv2D}, \n",
    "                   compile=False)\n",
    "\n",
    "# Load the labels\n",
    "class_names = open(\"C:/Users/youngjin/Desktop/캡디2024/labels.txt\", \"r\").readlines()\n",
    "\n",
    "# Set up serial communication with Arduino\n",
    "ser = serial.Serial('COM3', 9600)  # Replace 'COM3' with your Arduino's COM port\n",
    "time.sleep(2)  # Wait for the serial connection to initialize\n",
    "\n",
    "while True:\n",
    "    # Read from Arduino\n",
    "    if ser.in_waiting > 0:\n",
    "        line = ser.readline().decode('utf-8').rstrip()\n",
    "        print(\"Received:\", line)\n",
    "        \n",
    "        # Assuming the Arduino sends the image data in a specific format\n",
    "        # For example, if Arduino sends base64 encoded image data, you need to decode it\n",
    "        try:\n",
    "            # Decode the base64 string to bytes\n",
    "            image_data = base64.b64decode(line)\n",
    "            \n",
    "            # Convert bytes to a PIL image\n",
    "            image = Image.open(io.BytesIO(image_data))\n",
    "            \n",
    "            # Resize the image to (224, 224) pixels\n",
    "            resized_image = image.resize((224, 224))\n",
    "            \n",
    "            # Convert the image to a numpy array\n",
    "            image_array = np.asarray(resized_image, dtype=np.float32)\n",
    "            image_array = np.expand_dims(image_array, axis=0)\n",
    "            \n",
    "            # Normalize the image array\n",
    "            image_array = image_array / 255.0\n",
    "            \n",
    "            # Predict the model\n",
    "            prediction = model.predict(image_array)\n",
    "            index = np.argmax(prediction)\n",
    "            class_name = class_names[index]\n",
    "            confidence_score = prediction[0][index]\n",
    "\n",
    "            # Print prediction and confidence score\n",
    "            print(\"Class:\", class_name[2:], end=\"\")\n",
    "            print(\"Confidence Score:\", str(np.round(confidence_score * 100))[:-2], \"%\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"Error processing image:\", e)\n",
    "\n",
    "ser.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "import shutil\n",
    "from keras.models import load_model\n",
    "from keras.layers import DepthwiseConv2D\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import io\n",
    "import serial\n",
    "\n",
    "def unzip_files(zip_path, extract_path):\n",
    "    shutil.unpack_archive(zip_path, extract_path)\n",
    "\n",
    "zip_path1 = 'C:/Users/youngjin/Desktop/캡디2024/Cheese.v1i.createml.zip'\n",
    "zip_path2 = 'C:/Users/youngjin/Desktop/캡디2024/onion.v1i.createml.zip'\n",
    "extract_path = 'C:/Users/youngjin/Desktop/캡디2024'\n",
    "\n",
    "unzip_files(zip_path1, extract_path)\n",
    "unzip_files(zip_path2, extract_path)\n",
    "\n",
    "cheese = zip_path1\n",
    "bread = zip_path2\n",
    "\n",
    "# Load the model\n",
    "model = load_model(\"C:/Users/youngjin/Desktop/캡디2024/keras_model.h5\", \n",
    "                   custom_objects={'DepthwiseConv2D': DepthwiseConv2D}, \n",
    "                   compile=False)\n",
    "\n",
    "# Load the labels\n",
    "class_names = open(\"C:/Users/youngjin/Desktop/캡디2024/labels.txt\", \"r\").readlines()\n",
    "\n",
    "# Setup serial communication\n",
    "ser = serial.Serial('COM3', 115200, timeout=10)  # Replace 'COM3' with your serial port\n",
    "\n",
    "def predict_image(image):\n",
    "    # Preprocess the image for the model\n",
    "    image = np.asarray(image, dtype=np.float32)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = image / 255.0\n",
    "\n",
    "    # Predict the image\n",
    "    prediction = model.predict(image)\n",
    "    index = np.argmax(prediction)\n",
    "    class_name = class_names[index]\n",
    "    confidence_score = prediction[0][index]\n",
    "\n",
    "    return class_name.strip(), confidence_score\n",
    "\n",
    "def main():\n",
    "    while True:\n",
    "        # Read the image size\n",
    "        image_size_bytes = ser.read(4)\n",
    "        if len(image_size_bytes) != 4:\n",
    "            continue\n",
    "        \n",
    "        image_size = int.from_bytes(image_size_bytes, byteorder='little')\n",
    "\n",
    "        # Read the image data\n",
    "        image_data = ser.read(image_size)\n",
    "        if len(image_data) != image_size:\n",
    "            continue\n",
    "\n",
    "        # Load the image\n",
    "        image = Image.open(io.BytesIO(image_data))\n",
    "\n",
    "        # Predict the image\n",
    "        class_name, confidence_score = predict_image(image)\n",
    "\n",
    "        # Print the prediction result\n",
    "        print(f\"Class: {class_name}, Confidence Score: {confidence_score * 100:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "import shutil\n",
    "from keras.models import load_model\n",
    "from keras.layers import DepthwiseConv2D\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "import serial\n",
    "import time\n",
    "\n",
    "def unzip_files(zip_path, extract_path):\n",
    "    shutil.unpack_archive(zip_path, extract_path)\n",
    "\n",
    "zip_path1 = 'C:/Users/youngjin/Desktop/캡디2024/Cheese.v1i.createml.zip'\n",
    "zip_path2 = 'C:/Users/youngjin/Desktop/캡디2024/onion.v1i.createml.zip'\n",
    "extract_path = 'C:/Users/youngjin/Desktop/캡디2024'\n",
    "\n",
    "unzip_files(zip_path1, extract_path)\n",
    "unzip_files(zip_path2, extract_path)\n",
    "\n",
    "cheese = zip_path1\n",
    "bread = zip_path2\n",
    "\n",
    "\n",
    "# Load the model\n",
    "model = load_model(\"C:/Users/youngjin/Desktop/캡디2024/keras_model.h5\", \n",
    "                   custom_objects={'DepthwiseConv2D': DepthwiseConv2D}, \n",
    "                   compile=False)\n",
    "\n",
    "# Load the labels\n",
    "class_names = open(\"C:/Users/youngjin/Desktop/캡디2024/labels.txt\", \"r\").readlines()\n",
    "\n",
    "# Set up serial communication with Arduino\n",
    "ser = serial.Serial('COM3', 9600)  # Replace 'COM3' with your Arduino's COM port\n",
    "time.sleep(2)  # Wait for the serial connection to initialize\n",
    "\n",
    "while True:\n",
    "    # Read from Arduino\n",
    "    if ser.in_waiting > 0:\n",
    "        line = ser.readline().decode('utf-8').rstrip()\n",
    "        print(\"Received:\", line)\n",
    "        \n",
    "        # Assuming the Arduino sends the image data in a specific format\n",
    "        # For example, if Arduino sends base64 encoded image data, you need to decode it\n",
    "        try:\n",
    "            # Convert the image data string to a PIL image\n",
    "            image = Image.open(io.BytesIO(line))\n",
    "            \n",
    "            # Resize the image to (224, 224) pixels\n",
    "            resized_image = image.resize((224, 224))\n",
    "            \n",
    "            # Convert the image to a numpy array\n",
    "            image_array = np.asarray(resized_image, dtype=np.float32)\n",
    "            image_array = np.expand_dims(image_array, axis=0)\n",
    "            \n",
    "            # Normalize the image array\n",
    "            image_array = image_array / 255.0\n",
    "            \n",
    "            # Predict the model\n",
    "            prediction = model.predict(image_array)\n",
    "            index = np.argmax(prediction)\n",
    "            class_name = class_names[index]\n",
    "            confidence_score = prediction[0][index]\n",
    "\n",
    "            # Print prediction and confidence score\n",
    "            print(\"Class:\", class_name[2:], end=\"\")\n",
    "            print(\"Confidence Score:\", str(np.round(confidence_score * 100))[:-2], \"%\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"Error processing image:\", e)\n",
    "\n",
    "ser.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "import serial\n",
    "import numpy as np\n",
    "import io\n",
    "from PIL import Image\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "# 시리얼 포트 초기화\n",
    "ser = serial.Serial('COM3', 115200)  # 시리얼 포트와 속도를 맞춰줘야 함\n",
    "time.sleep(2)  # 시리얼 연결이 초기화될 때까지 대기\n",
    "\n",
    "# 모델 로드\n",
    "model = load_model(\"C:/Users/youngjin/Desktop/캡디2024/keras_model.h5\", \n",
    "                   custom_objects={'DepthwiseConv2D': DepthwiseConv2D}, \n",
    "                   compile=False)\n",
    "\n",
    "# 레이블 로드\n",
    "class_names = open(\"C:/Users/youngjin/Desktop/캡디2024/labels.txt\", \"r\").readlines()\n",
    "\n",
    "def process_image(image_data):\n",
    "    # 바이트 데이터를 이미지로 변환\n",
    "    image = Image.open(io.BytesIO(image_data))\n",
    "    image = image.resize((224, 224))\n",
    "    image_array = np.asarray(image, dtype=np.float32)\n",
    "    image_array = np.expand_dims(image_array, axis=0)\n",
    "    image_array = image_array / 255.0\n",
    "    return image_array\n",
    "\n",
    "while True:\n",
    "    # 시리얼 데이터 수신\n",
    "    if ser.in_waiting > 0:\n",
    "        photo_data = ser.read(ser.in_waiting)\n",
    "        \n",
    "        # 이미지 데이터 처리\n",
    "        try:\n",
    "            processed_image = process_image(photo_data)\n",
    "            \n",
    "            # 모델 예측\n",
    "            prediction = model.predict(processed_image)\n",
    "            index = np.argmax(prediction)\n",
    "            class_name = class_names[index]\n",
    "            confidence_score = prediction[0][index]\n",
    "\n",
    "            # 예측 결과 출력\n",
    "            print(f\"Class: {class_name[2:]}, Confidence Score: {str(np.round(confidence_score * 100))[:-2]}%\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image: {e}\")\n",
    "\n",
    "ser.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**url**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial\n",
    "import numpy as np\n",
    "import io\n",
    "from PIL import Image\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "# 시리얼 포트 초기화\n",
    "ser = serial.Serial('COM3', 115200)  # 시리얼 포트와 속도를 맞춰줘야 함\n",
    "time.sleep(2)  # 시리얼 연결이 초기화될 때까지 대기\n",
    "\n",
    "# 모델 로드\n",
    "model = load_model(\"C:/Users/youngjin/Desktop/캡디2024/keras_model.h5\", \n",
    "                   custom_objects={'DepthwiseConv2D': DepthwiseConv2D}, \n",
    "                   compile=False)\n",
    "\n",
    "# 레이블 로드\n",
    "class_names = open(\"C:/Users/youngjin/Desktop/캡디2024/labels.txt\", \"r\").readlines()\n",
    "\n",
    "def process_image(image_data):\n",
    "    # 바이트 데이터를 이미지로 변환\n",
    "    image = Image.open(io.BytesIO(image_data))\n",
    "    image = image.resize((224, 224))\n",
    "    image_array = np.asarray(image, dtype=np.float32)\n",
    "    image_array = np.expand_dims(image_array, axis=0)\n",
    "    image_array = image_array / 255.0\n",
    "    return image_array\n",
    "\n",
    "def predict_image():\n",
    "    while True:\n",
    "        # 시리얼 데이터 수신\n",
    "        if ser.in_waiting > 0:\n",
    "            photo_data = ser.read(ser.in_waiting)\n",
    "            \n",
    "            # 이미지 데이터 처리\n",
    "            try:\n",
    "                processed_image = process_image(photo_data)\n",
    "                \n",
    "                # 모델 예측\n",
    "                prediction = model.predict(processed_image)\n",
    "                index = np.argmax(prediction)\n",
    "                class_name = class_names[index]\n",
    "                confidence_score = prediction[0][index]\n",
    "\n",
    "                # 예측 결과 출력 및 반환\n",
    "                print(f\"Class: {class_name[2:]}, Confidence Score: {str(np.round(confidence_score * 100))[:-2]}%\")\n",
    "                return class_name[2:]  # 예측된 클래스 이름 반환\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predicted_class = predict_image()\n",
    "    ser.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from predict_image import predict_image  # 모델 예측 함수를 import\n",
    "\n",
    "def food_info(name):\n",
    "    url = f\"https://www.10000recipe.com/recipe/list.html?q={name}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "    else:\n",
    "        print(\"HTTP response error:\", response.status_code)\n",
    "        return\n",
    "\n",
    "    food_list = soup.find_all(attrs={'class':'common_sp_link'})\n",
    "    if not food_list:\n",
    "        print(\"식재료에 맞는 레시피가 없습니다.\")\n",
    "        return\n",
    "\n",
    "    food_id = food_list[0]['href'].split('/')[-1]\n",
    "    new_url = f'https://www.10000recipe.com/recipe/{food_id}'\n",
    "    new_response = requests.get(new_url)\n",
    "    if new_response.status_code == 200:\n",
    "        html = new_response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "    else:\n",
    "        print(\"HTTP response error:\", new_response.status_code)\n",
    "        return\n",
    "\n",
    "    food_info = soup.find(attrs={'type':'application/ld+json'})\n",
    "    result = json.loads(food_info.text)\n",
    "    ingredient = ','.join(result['recipeIngredient'])\n",
    "    recipe = [result['recipeInstructions'][i]['text'] for i in range(len(result['recipeInstructions']))]\n",
    "    for i in range(len(recipe)):\n",
    "        recipe[i] = f'{i+1}. ' + recipe[i]\n",
    "\n",
    "    title = soup.title.string\n",
    "\n",
    "    res = {\n",
    "        'name': title,\n",
    "        'ingredients': ingredient,\n",
    "        'recipe': recipe\n",
    "    }\n",
    "\n",
    "    return res\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predicted_ingredients = predict_image()  # 모델 예측 함수 호출\n",
    "    if predicted_ingredients:\n",
    "        ingredients_str = \" \".join(predicted_ingredients)  # 예측된 식재료를 공백으로 구분된 문자열로 변환\n",
    "        food_info_result = food_info(ingredients_str)\n",
    "        if food_info_result:\n",
    "            print(\"Food Name:\", food_info_result['name'])\n",
    "            print(\"Ingredients:\", food_info_result['ingredients'])\n",
    "            print(\"Recipe:\")\n",
    "            for step in food_info_result['recipe']:\n",
    "                print(step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "부트캠프 문제풀이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10! = 1\n",
      "10! = 2\n",
      "10! = 6\n",
      "10! = 24\n",
      "10! = 120\n",
      "10! = 720\n",
      "10! = 5040\n",
      "10! = 40320\n",
      "10! = 362880\n",
      "10! = 3628800\n"
     ]
    }
   ],
   "source": [
    "fact = 1\n",
    "num = 1\n",
    "while num <= 10:\n",
    "    fact = num * fact\n",
    "    print(f\"10! = {fact}\")\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "cm        mm        m        inch\n",
      "-----------------------------------\n",
      "1         10        0.01      0.39      \n",
      "2         20        0.02      0.79      \n",
      "3         30        0.03      1.18      \n",
      "4         40        0.04      1.57      \n",
      "5         50        0.05      1.97      \n",
      "6         60        0.06      2.36      \n",
      "7         70        0.07      2.76      \n",
      "8         80        0.08      3.15      \n",
      "9         90        0.09      3.54      \n",
      "10        100       0.1       3.94      \n",
      "11        110       0.11      4.33      \n",
      "12        120       0.12      4.72      \n",
      "13        130       0.13      5.12      \n",
      "14        140       0.14      5.51      \n",
      "15        150       0.15      5.91      \n",
      "16        160       0.16      6.3       \n",
      "17        170       0.17      6.69      \n",
      "18        180       0.18      7.09      \n",
      "19        190       0.19      7.48      \n",
      "20        200       0.2       7.87      \n",
      "21        210       0.21      8.27      \n",
      "22        220       0.22      8.66      \n",
      "23        230       0.23      9.06      \n",
      "24        240       0.24      9.45      \n",
      "25        250       0.25      9.84      \n",
      "26        260       0.26      10.24     \n",
      "27        270       0.27      10.63     \n",
      "28        280       0.28      11.02     \n",
      "29        290       0.29      11.42     \n",
      "30        300       0.3       11.81     \n",
      "31        310       0.31      12.2      \n",
      "32        320       0.32      12.6      \n",
      "33        330       0.33      12.99     \n",
      "34        340       0.34      13.39     \n",
      "35        350       0.35      13.78     \n",
      "36        360       0.36      14.17     \n",
      "37        370       0.37      14.57     \n",
      "38        380       0.38      14.96     \n",
      "39        390       0.39      15.35     \n",
      "40        400       0.4       15.75     \n",
      "41        410       0.41      16.14     \n",
      "42        420       0.42      16.54     \n",
      "43        430       0.43      16.93     \n",
      "44        440       0.44      17.32     \n",
      "45        450       0.45      17.72     \n",
      "46        460       0.46      18.11     \n",
      "47        470       0.47      18.5      \n",
      "48        480       0.48      18.9      \n",
      "49        490       0.49      19.29     \n",
      "50        500       0.5       19.69     \n"
     ]
    }
   ],
   "source": [
    "x= 0.393701\n",
    "q= 6\n",
    "print(\"-\" *35)\n",
    "print(\"cm\",\" \"*q,\"mm\",\" \"*q,\"m\",\" \"*q,\"inch\")    \n",
    "print(\"-\" *35)\n",
    "\n",
    "\n",
    "for cm in range(1,51):\n",
    "    mm = cm * 10 \n",
    "    m = round(cm * 0.01,2)\n",
    "    inch = round(cm * x,2)\n",
    "    print(f\"{cm:<10}{mm:<10}{m:<10}{inch:<10}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
